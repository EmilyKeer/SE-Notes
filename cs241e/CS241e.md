# CS 241e
### Foundations of Sequential Programs Enriched

Prof. Ondr̂ej Lhoták


## Introduction
### Bits
- Have no assigned meaning by themselves

#### Conventions
There are infinitely many integers, but only 2<sup>32</sup> can be represented on a 32-bit system, so arithmetic is done on the finite ring of equivalence classes mod 2<sup>32</sup>.

#### Numeric Interpretation
- As an unsigned integer, there are 2<sup>32-1</sup> integers in a 32-bit int
- In Two's Complement signed integers, the first bit is the sign bit
  - Addition, multiplication, and subtraction are the same as on integers
  - Division and magnitude comparison need separate operations for unsigned and Two's Complement numbers

### Our Computer
The computer we're using happens to have state equivalent to {0, 1}<sup>2<sup>26</sup> + 32 * 34</sup>

```
+------------------------------------------------+          Memory
|                                                |            32
|                            Registers           |    0 +-----------+
|   +-----------------+          32              |    4 |           |
|   |   Control Unit  |    +---------------+     |    8 |           |
|   |                 |   1| 0 1 0 ...     |     |    12|           |
|   +-----------------+   2| 1             |     | ->   |           |
|   |       ALU       |   .| 0             |     |      |           |
|   |                 |   .|               |34   |      |           |
|   |                 |  31|               |     |    . |           |
|   |                 |  LO|               |     |    . |           |
|   |                 |  HI|               |     |    . |           |
|   +-----------------+  PC+---------------+     |      |           |
|                                                |      +-----------+
+------------------------------------------------+   2^24-4
```
PC = program counter (the register we're on)

The CPU implements a function `step`:
```
step: state -> state
s_(i+1) = step(s_i)
Def: step*(s) = if (step(s) defined) step*(step(s)) else s

input
  | encode
  v       step*
  s_0 -----------> s_n

Want:
For all i, f(i) = decode(step*(encode(i)))

(program, input)           (program, data)      
       |                         ^
       | encode (compiler)       | decode
       |                         |
       v         step*           |
       s_0 -------------------> s_n
```

#### Definitions
A **stored program computer (von Neumann machine)** includes the program as part of its input
- `step` should be general
  - `sem*(program, input) = decode( step*( encode(program, input) ) )`
  - `sem ((lambda (x) e) v)`
    - `[x |-> v] e`
    - `x` gets sustituted with `v` in `e`

**Semantics**: meaning of a program
- **operational semantics**: semantics defined in terms of a function that transforms state
  - an interpreter, basically

#### Defining step functions
```scala
def step(state) = {

  // fetch
  instruction = state.memory[state.register[PC]]

  // increment PC
  state2 = state.setRegister(PC, state.register(PC)+4)

  // decode, execute
  instruction.match {
    // ...
  }
}
```

### MIPS
Reference: https://www.student.cs.uwaterloo.ca/~cs241/mips/mipsref.pdf
- When a word is stored to memory location 0xffff000c, the least-significant byte (eight bits) of the word are sent to the standard output.
- Loading a word from memory location 0xffff0004 places the next byte from standard input into the least-significant byte of the destination register.

Definitions:
- An **opcode** is a short name for a machine language instruction
- **Assembly language** is a language for writing machine language programs with opcodes
- An **assembler** is a program that translates assembly language to machine language

## Compiler features
### Labels
An abstraction of memory addresses

e.g.: absolute value
```assembly
SLT 2, 1, 0
BEQ 2, 0, 1
SUB 1, 0, 1
JR 31
```

Same example, using labels:
```assembly
SLT 2, 1, 0
BEQ 2, 0, label
SUB 1, 0, 1
Define label
JR 31
```

e.g. a procedure
```assembly
... ; main
... ; program
LIS 1
USE label
JALR 1
...

DEFINE label
... ; procedure
...
...
JR 31
```

To compile out labels, we need two passes:
1. Determine the address of each label
2. Generate code for all the instructions with labels converted to their corresponding addresses

#### Relocation, Linking
An **object file** is a file that contains:
- machine language code
- metadata recording how labels were used before the translation to machine language

**Relocation** is the process of adjusting machine language code using object file metatada so that it can be loaded at a different address by:
- reverse-engineering labels
- reassembling at a new address

**Linking** is the process of combining multiple object files into a machine code program
- To link assembly language files, just concatenate them together
- To link object files:
  - reverse-engineer the labels from the metadata
  - relocation, label resolution across different files
  - concatenate assembly language programs
  - reassemble them to machine language

Typical C build process:
```
C source              Assembly        Object
files              files           files
a.c -----------> a.s -----------> a.o ---+
   Compiler (cc)    Assembler (as)       |
                                         |
b.c -----------> b.s -----------> b.o ---+--> linker (ld) ------> executable machine language program
                                         |
                                         |
c.c -----------> c.s -----------> c.o ---+
```

### Variables
A **variable** is an abstraction of a storage location (register, *fixed* or *dynamically determined* address in memory) that can hold a value

Read from address ALPHA to $1:
```assembly
LIS 2
WORD ALPHA ; Saves address ALPHA into register 2
LW 1, 0, 2 ; Loads value from memory address ALPHA into register 1
```

#### Variable instances
e.g.
```scala
def fact(x: Int): Int = if (x < 2) 1 else x*fact(x-1)
fact(3)
// fact(3) = 3 * fact(2) = 3 * 2 * fact(1) = 3*2*1 = 6
// Three instances of x occur in this execution
```

```
               fact(1)
               +--------+
       fact(2) |        |
       +-------+        +-------+
fact(3)|                        |
-------+                        +--------
                 time -->
```

The **extent** of a variable instance is the time interval in which it can be accessed

e.g.
- procedure-level variable: execution of procedure
- global variable: entire execution of program
- field of object/record: from he time that object is allocated to time it is deallocated/freed (explicitly or automatically with GC)

#### The Stack
The extent of local variables begin and end in a **last in, first out** order. A **stack** allows us to create and destroy storage locations this way.

##### Implementation
- Designate a variable (register, usually; R30 in this course) to hold the address at the top of the stack (the **stack pointer**)
- To push to stack: decrement stack pointer by 4
- To pop from stack: increment stack pointer by 4

After entering a procedure with variables a, b, c
```
                  memory
               +-----------+
               |           |
               +-----------+
               |    42     |
               +-----------+
      SP = 100 |     a     | \
               +-----------+ |
           104 |     b     | | stack frame (all local
               +-----------+ | vars from procedure)
           108 |     c     | /
               +-----------+
           112 |   stack   |
               +-----------+
```

e.g. read variable c at offset 8 from SP
```assembly
LW 1, 8, 30 ; 8, 30 = offset, register
```

Definitions
- **Symbol table**: a map from variables to offsets
- **Frame pointer**: a copy of the stack pointer that stays fixed for the duration of a procedure call. It enables us to use the stack for other purposes within the procedure
- Convention: use R30 for stack pointer, R29 for frame pointer; bottom of stack is at the end of memory

In this course, all data in memory will be in **chunks**
- areas of consecutive memory locations
- indexed by variables (symbol table)
- base register
- can generate code to read/write variables

### Evaluating expressions
e.g. `a*b + c*d`

#### Technique 1 (stack)
```
t1 = a*b
t2 = c*d
t3 = t1+t2
```

```scala
def evaluate(e1, op, e2): Code = {
  evaluate(e1)
  push $3
  evaluate(e2)
  pop $4
  $3 = $4 op $3
}
def evaluateVar(v: Variable): Code = read v (into $3)
```
- general
- inefficient
- difficult to transform further

#### Technique 2 (temporary variables)
```
t1 = a*b
t2 = c*d    // generate code to eval e1 op e2, put result in some variable
t3 = t1+t2  // return code, variable
```

```scala
def evaluate(e1, op, e2): (Code, Variable) = {
  (code1, var1) = evaluate(e1)
  (code2, var2) = evaluate(e2)
  v3 = new Variable
  code = block(code1, code2, var3 = var1 op var2)
  return (code, var3)
}
```
- flexible, easy to transform
- machine language operations require registers, so many variables means inefficient use of memory/registers

**Register allocation** is the process of assigning variables to real registers or memory addresses (abstract)
- Minimize the number of registers/memory locations used by **sharing them** among non-interfering variables.

```
+------------------+                 +----------------+
|       Code       |                 | IR with real   |
|Intermediate      |---------------->| registers      |
|Representation    |  register       | addresses/     |
|with virtual regs |  allocation     | offsets        |
+------------------+                 +----------------+
```

#### Technique 3 (hybrid) (temp vars, but operations on real registers)

```
t1 = a*b  // $4 = a, $3 = b, $3 = $4 * $3, t1 = $3
t2 = c*d
t3 = t1+t2
```
```scala
// generated code leaves result in $3
def evaluate(e1 op e2):Code = {
  val t1 = new Variable
  block(
    evaluate(e1),
    write(t1, 3),
    evaluate(e2),
    read(4, t1),
    $3 = $4 op $3
  )
}
```

#### Register allocation
e.g. a+b+c+d+e
- A variable is **live at program point p** if the value that it holds at p may be read sometime after p.
- The **live range** of a variable is the set of program points where it is live.
  - The start of a live range is always just after a write
  - The end of a live range is always just after a read
- Two variables can share the same register iff their live ranges do not intersect.

##### e.g.
t1 = a * b
- t1 live
t2 = c * d
- t1, t2 live
t3 = t1 * t2
- t3 live
e = t3


##### e.g.
t1 = a * b
- t1 live
t2 = c * d
- t1, t2
t3 = t1 + t2
- t3
t4 = e * f
- t3, t4
t5 = t3 - t4
- t3, t5
g = t3 + t5

- reg1: t1, t3
- reg2: t2, t4, t5

- r1 = a * b

- r2 = c * d
- r1 = r1 + r2
- r2 = e * f
- r2 = r1 - r2
- g = r1 + r2

### Inference graph
- Vertices are variables
- Edge from (v1 - v2) if v1 and v2 conflict (both live at the same program point)
- A **colouring** assigns a colour to each vertex so that every edge connects vertices of distinct colours
  - each colour corresponds to a register, so colouring is a register assignment
  - Finding a minimal colouring of an arbitrary graph is NP-hard.
- A simple greedy algorithm (not optimal):
  - For each vertex v, colour v with the smallest colour not yet used by its neighbours
- Many graphs (SSA form inference graphs) have special structure that enables efficient algorithms


### Control structures
If statements
```scala
if (e1, op, e2, then, else) => {
  withTempVar{t1 =>
    evaluate(e1)
    t1 = $3
    evaluate(e2)
    $4 = t1
    evaluate op
    T
    beq
    define(else)
    E
    define(end)
  }
}
```

### Procedures
A **Procedure** is an abstraction that encapsulates a reusable sequence of code
- calling code and procedure agree on conventions
  - where (memory/registers) to pass arguments and return value
  - which registers procedures may modify (caller-save) or preserve (callee-save)
- calling code **transfers control** to the procedure (modifies PC)
- calling code passes arguments for parameters
- procedure transfers control back to caller
- returns a value

#### e.g.
Caller | Procedure (callee)
-------|-------------------
 | `Define(proc)`
 | `Reg.savedParamPtr = Reg.allocated`
 | `stack.allocate(frame)`
evaluate args in temp vars |
`Stack.allocate(parameters)` | 
copy arguments from temp vars into parameter chunk |
 | `dynamicLink = Reg.fp` (29)
 | `savedPC = Reg.savedPC` (31)
 | `Reg.fp = Reg.allocated` (6)
 | `paramPtr = Reg.savedParamPtr` (get it out of a register)
`LIS(Reg.targetPC)` | `body`
`Use(proc)` | 
`JALR(Reg.targetPC)` | `Reg.savedPC = savedPC`
 | `Reg.fp = dynamicLink`
 | `stack.pop //frame`
 | `stack.pop //parameters`
 | `JR(31)`

A **prologue/epilogue** are the instructions at the beginning or end of a procedure

#### Conventions:
- Modifies: 31, 6, 5, all others
- Preserves: 30 (sp), 29 (fp)
- Caller allocates chunk for arguments
  - puts address in Reg.allocated
- Callee allocates and frees chunk for variables

### Eliminating variable accesses (A5)
- If v is a variable (including a temp var) of the procedure:
  - Access v in the frame chunk (A3)
- Otherwise, v is a parameter:
  - read param pointer from normal chunk into Reg.scratch (4)
  - access v in parameter chunk (with base register Reg.scratch that param ptr was read into)

### Nested Procedures
e.g.
As a loop:
```scala
def m() = {
  var i = 0
  var j = 0
  while (i < 10) {
    i = i + 1
    j = j + i
  }
  i + j
}
```
As a procedure:
```scala
def m() = {
  var i = 0
  var j = 0
  def loop() = {
    if (i < 10) {
      i = i + 1
      j = j + i
      loop()
    }
  }
  loop()
  i + j
}
```

e.g.
```scala
def f() = {
  val x = 2
  val w = 5
  def g() = {
    val y = 3
    val w = 7
    x + y + h()
  }
  def h() = {
    val z = 4
    z + w
  }
  g()
}
```
- A **dynamic link** is a pointer to the frame of the procedure that called the currently executing procedure.
- **static (lexical) scope:** names are resolved in statically enclosing procedures in source code
  - For this course, we will implement static scope
- **dynamic scope:** names resolved in dynamically calling procedures (in the runtime stack of calls)

```
        Frame
      +--------+
   h  |        |      Params
      |   pp   | --> +-------+
      |   dl   |     |       |
      +--------+     |  sl   | ------+
          |          +-------+       |
          v                          |
      +--------+                     |
   g  |        |                     |
      |   pp   | --> +-------+       |
      |   dl   |     |       |       |
      +--------+     |  sl   | ------+
          |          +-------+       |
          v                          |
      +--------+ <-------------------+
   f  |        |
      |   pp   | --> +-------+
      |   dl   |     |       |
      +--------+     |  sl   |
                     +-------+
```
- The **static link** is a pointer to the frame of the statically enclosing procedure (of the currently executing procedure)
- The **nesting depth** of a procedure is the number of outer procedures that it is nested in
  - *TODO:* Add `nestingDepth` to `Procedure`

```
f()={
  g()={}
  h()={
    k()={}
  }
}
```

- To compute the static link at a call site:
  - `depth(sl target) = depth(call target) - 1`
  - `let n = depth(current procedure) - depth(sl target)`
  - `n == depth(current procedure) - depth(sl target)`
  - `n == depth(current procedure) - depth(call target) + 1`
  - If `n == 0`, pass fp as sl.
  - Otherwise, follow sl n times, and pass the result as sl
  - e.g.
    - f calls g: n=0, pass fp as sl of g
    - g calls h: n=1, pass sl of g as sl of h
    - k calls g: n=2, pass sl of sl of k as the sl of g
    - f calls k: n=-1, not allowed

#### Variable Access (eliminateVarAccessesA6)
```
let n = depth(current procedure) - depth(proc declaring var)
```
Follow static link n times, then look for variable

### Midterm
Review: Oct 28 in the tutorial

#### Topics
- bits, binary, two's complement
- MIPS, CPU/registers/memory
  - step fetch/increment/execute
- machine language
- operational semantics
- labels/assembly language/symbol table
- relocation/linking
- variables, extent
- stack, frame pointer
- evaluating expressions, if, while
- register allocationlive variables
- procedures: conventions, prologue/epilogue, calling of
- nested procedures, static link

### First-Class Functions
```scala
def procedure(x: Int) = { x + 1 }
var increase: (Int)=>Int = procedure
increase = { x => x+2 }
def twice(fun: (Int)=>Int): (Int)=>Int = {
  x => fun(fun(x))
}
increase = twice(increase)
def increaseBy2(increment: Int): (Int)=>Int {
  def procedure(x: Int) = {x + increment}
  procedure
}
```

#### Free variables
A **free variable** in some expression is a variable that is not bound (defined) in that expression.
- `x` is free in `x + increment`
- `x` is not free in `{x => x + increment}`
- `increment` is free in `{x => x + increment}`
- `increment` is no longer free in `def increaseBy(increment: Int): (Int)=>Int = {x => x + increment}`

An expression is **closed** if it contains no free variables.
- A **closure** is a pair of:
  - a function value
  - an environment for the free variables in the function body

The closure **closes over** its environment

#### Stack vs Heap
```scala
def constructor(a: Int): (Int)=>Int = {
  var b = a*2
  def procedure(c: Int): Int = {
    a+b+c
  }
  procedure //closure creation: will be represented by a `Closure` for us
}
var functionValue: (Int)=>Int = constructor(42)
functionValue(5)
```

- `constructor(42)` is a regular call (`Call` in our compiler), specifies a `Procedure`
- `functionValue(5)` is a closure call (`CallClosure` in our compiler)

The extent of `a` and `b`:
- begins at the beginning of the constructor
- ends when all copies of the closure have been lost/overwritten, *not* when the constructor finishes
- Therefore we can't put the frame from the constructor on the stack
The **heap** is a data structure that manages memory so that it can be allocated and freed at arbitrary times

#### Implementation
After closure creation, store:
- Address of code that implements the closure
  - Label
- environment
  - static link

To call a closure, pass environment as the static link.
- Compute the environment/static link in the same way as if we were calling the procedure at the closure creation site

- A closure can access frames of all procedures that it is nested in
- If `p` is nested in `p'` and we ever create a closure from `p`, then the frame of `p'` must be on the heap (and all of the outer procedures of `p'`)
  - A better compiler does lifetime analysis
    - determine the extent of each variable
    - split the frame between stack and heap

#### Objects
```scala
class Counter {
  private var value = 0
  def get() = value
  def incrementBy(amount: Int) = {
    value = value + amount
  }
}

val c = new Counter
c.incrementBy(42)
c.incrementBy(-5)
c.get()

def newCounter: (()=>Int, (Int)=>Unit) = {
  var value = 0
  def get() = value
  def incrementBy(amount: Int) = {
    value = value + amount
  }
  (get, incrementBy)
}
val c2 = newCounter
c2._2(42)
c2._2(-5)
c2._1()
```

- An **object** is a data structure that has:
  - state (data)
  - behaviour (procedures)
- Alternatively, an object is jist:
  - a collection of closures (procedures)
  - a common environment (data)

### Tail calls
This will overflow the stack if there's a large number of recursion and we don't make it a tail call:

```scala
def m() = {
  var i = 0
  var j = 0
  def loop() = {
    if (i < 10000000) {
      i = i + 1
      j = j + i
      loop()
    }
  }
  loop()
  i + j
}
```

A call is a **tail call** if it is the last action before the epilogure
- may be nested inside multiple `if`s
- tail call transformation is *not safe* if calling a nested procedure

```scala
def f() = {
  var v = ???
  def g() = {
    // do something with v
  }
  // epilogue?
  g()
}
```

#### Implementation
Before | After tail call transformation | Notes
-------|--------------------------------|------
 | evaluate arguments | 
(call loop) | allocate parameters (1) (of callee/target) | 
evaluate arguments | write arguments into parameters | 
allocate parameters |  | 
write arguments into parameters |  | 
`LIS(8)` | | 
`Use(label)` | | 
`JALR(8)` |  | 
(epilogue) | (epilogue) | 
`Reg.savedPC = savedPC` | `Reg.savedPC = savedPC` | 
`Reg.fp = dynamicLink` | `Reg.fp = dynamicLink` | 
pop (frame) |  | 
pop (parameters) |  | 
`JR(31)` |  | 
 | pop (new parameters (1)) | 
 | pop (frame) | 
 | pop (parameters of caller) | 
 | allocate parameters (2) (of callee/target) | 
 | copy parameters (1) to (2) | This is ok because nothing should have written to this memory space yet 
 | | Also, make sure you copy from the bottom up to make sure you don't overwrite anything
 | `LIS(8)` | 
 | `Use(label)` | 
 | `JR(31)` | 

What if the caller and/or callee frame is on the heap instead of the stack?
- don't pop from the stack when the frame is actually on the heap
**Tail recursion** is a special case of a tail call that calls the same caller procedure (the procedure calls itself)

## Formal Languages
(CS 360, 365, 462)

- specification (prove/disprove word is in the language)
- recognition (language, word) =&gt; Boolean (not always possible)
  - autogenerate recognizer from specification
- interpretation (language, word) =&gt; meaning (data structure)

**alphabet(&Sigma;)**: finite set of symbols
e.g. {a, b, c, ..., z}, {0, 1, ..., 9}, {0, 1}, {def, var, val, ..., =, (, ), ...}

**word** (over &Sigma;): finite sequence of symbols
e.g. hello, 42, 1010101, def proc(), &epsilon; (sequence of length 0 - empty word)

**language**: set of words (possibly infinite)
e.g.
- all binary strings of 32 bits
- all prime numbers written in decimal
- all correct solutions to A6, A7
- {} != {&epsilon;}

A **language class** is a collection of languages
- finite languages
- regular languages
- context-free languages
- undecidable languages

### Deterministic Finite Automata
```
                   v──┐
start ┌──┐  a   ╔═══╗ │b   ┌──────┐
   ──>│  ├─────>║   ╟─┘    │      │
      │  │      ║   ╟─────>│error │
      └──┘      ╚═══╝      └──────┘
              accepting/
              final state

```

- If each letter in the word goes to another state, it is in the language
- If the word doesn't end in an accepting state, it is not in the language
- If the word requires a transition that doesn't exist, it is not in the language

- &Sigma; = { a,b }
  - abb &isin; L
  - a &isin; L
  - aa &notin; L
  - &Epsilon; &notin; L

e.g.
&Sigma; = {a, b} where all words with an even number of `a`s are in the language
```
    ┌─────┐  ┌───────────┐
   b│     │  v     a     │
    │   ┌─┴────┐       ╔═╧════╗
 ───┴──>│ odd  │       ║ even ║<──┐
        └────┬─┘       ╚════╤═╝   │
             │     a     ^  │     │b
             └───────────┘  └─────┘
```

A **DFA** is a 5-tuple (&Sigma;, Q, q<sub>0</sub>, A, &delta;) where:

Symbol | Meaning | Example
-------|---------|--------
&Sigma; | input alphabet | &Sigma; = { a, b }
Q | a *finite* set of states | Q = { odd, even }
q<sub>0</sub> &isin; Q | start state | q<sub>0</sub> = even
&delta; : Q x &times; &rarr; Q | transition function (partial, not defined for all of domain) | &delta;(even, a) = odd
 | | &delta;(even, b) = even
 | | &delta;(odd, a) = even
 | | &delta;(odd, b) = odd

- &delta;\* : Q &times; &Epsilon;* &rarr; Q
- &delta;\*(q, &epsilon;) = q
- &delta;\*(q, first::rest) = &delta;\*(&delta;(q, first), rest)

- A word w is **accepted by the DFA** if &delta;\*(q<sub>0</sub>, w) &isin; A
- The **language specified by the DFA** is the set of all words accepted by the DFA
- A language is **regular** if there exists some DFA specifying that language
  - Every finite language is regular
  - Given a language, there may be multiple DFAs specifying it, but the minimal DFA (minimum number of states) for the language is unique

### Non-Deterministic Finite Automata

e.g.
```
DECIMAL NUMBERS
        ┌───┐ 0 ╔══╗
      ┌─┴┐  └──>║  ║
   ──>│  │      ╚══╝
      └─┬┘        v──┐
        └───┐   ╔══╗ │0-9
         1-9└──>║  ╟─┘
                ╚══╝

HEXADECIMAL NUMBERS
                    ┌──┐
                    v  │0-9,A-F
    ┌──┐ 0 ┌──┐ x ╔══╗ │
 ──>│  ├──>│  ├──>║  ╟─┘
    └──┘   └──┘   ╚══╝

ALL NUMBERS
        ┌───┐ 0 ╔══╗
      ┌─┴┐  └──>║  ║
   ──>│  │      ╚══╝
      └┬┬┘        v──┐
      ┌┘└───┐   ╔══╗ │0-9
      │  1-9└──>║  ╟─┘
      │         ╚══╝
     0│             ┌──┐
      └─────v       v  │0-9,A-F
           ┌──┐ x ╔══╗ │
           │  ├──>║  ╟─┘
           └──┘   ╚══╝
```
**Non-determinism** is when the algorithm has a choice of multiple paths
How does one choose the right path?
- Assume there exists an "oracle" who knows the right path
- Try all paths

An NFA is a 5-tuple (&Sigma;, Q, q<sub>0</sub>, A, &delta;), same as a DFA, *except:*
- DFA: &delta;: Q &times; &Sigma; &rarr; Q
- NFA: &delta;: Q &times; &Sigma; &rarr; 2<sup>Q</sup> (set of states)
  - &delta;\*: Q &times; &Sigma;\*  &rarr; 2<sup>Q</sup>
  - &delta;\*(q, &epsilon;) = {q}
  - &delta;\*(q, first::rest) = &cup;<sub>q' &isin; &delta;(q, first)</sub> &delta;*(q', rest)
    - This means for every q' &isin; &delta;(q, first), take the union of &delta;*(q', rest)

A word is **accepted by the NFA** if &delta;*(q<sub>0</sub>, w) &cap; A &ne; {}

#### &epsilon; Transitions
Whenever we are in state A, we may (but don't have to) move to state B. (E = &epsilon; in the diagram)
- For every transition into A, add the same transition into B, then remove the &epsilon;-transition.

```
  ┌───┐ E ┌───┐
  │ A ├──>│ B │
  └───┘   └───┘
        ║
        ║
        v
    ┌─────────────┐
  ┌─┤             v
  └─┴───>┌───┐   ╔═══╗
         │ A │   ║ B ║
  ┌─┬───>└───┘   ╚═══╝
  └─┤             ^
    └─────────────┘

```

### Regular Expressions
Regular Expression | Meaning
-------------------|---------
&epsilon; | L(&epsilon;) = {&epsilon;}
R<sub>1</sub> \| R<sub>2</sub> where R<sub>1</sub>, R<sub>2</sub> are REs | L(R<sub>1</sub>\|R<sub>2</sub>) = L(R<sub>1</sub>) &cup; L(R<sub>2</sub>)
R<sub>1</sub>R<sub>2</sub> where R<sub>1</sub>, R<sub>2</sub> are REs |  L(R<sub>1</sub>R<sub>2</sub>) = {xy \| x &isin; L(R<sub>1</sub>), y &isin; L(R<sub>2</sub>)}
R\* where R is a RE | L(R\*) = {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub> \| &forall;i . x<sub>i</sub> &isin; L(R), n&ge;0}

Example | Meaning
--------|--------
(a\*)\|(b*\) | sequence of `a`s or a sequence of `b`s
a\*b\* | some number of `a`s followed by some number of `b`s
(a\|b)\* | any string over &Epsilon; = {a, b}
a(a\*) | 1 or more `a`s
(aa)\* | even number of `a`s
(a\|b)\*aa(a\|b)\* | all strings containing aa over &Epsilon; = {a, b}
(b\|ab)*(a\|&epsilon;) | all strings not containing aa

### Kleene's Theorem
For a language L, the following statements are equivalent:

1. &exist; a DFA specifying L
2. &exist; an NFA without &epsilon;-transitions specifying L
3. &exist; an NFA with &epsilon;-expressions specifying L
4. &exist; a regular expression specifying L
5. L is a regular language

### Scanning
- **Recognition**: is a word w in the language L?
- **Scanning**: split a string into tokens
  - input: string w, language L
  - output: sequence of words w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub> such that
    - w<sub>1</sub>w<sub>2</sub>...w<sub>n</sub> = w, and
    - &forall;i . w<sub>i</sub> &isin; L
    - for each i, w<sub>i</sub> is the longest prefix of w<sub>i</sub>w<sub>i+1</sub>...w<sub>n</sub> that is still in L
  - A word w can be scanned if and only if w &isin; L*
    - Or, w &isin; L(R*), where R is a Regular Expression for L

Scanning output is not always unique
- L = {a, aa}
- If w = aa, the scan result can be [aa] or [a, a]

#### maximal Munch (Greedy) Scanning
A common hack: Bite off the largest piece of w possible at each step

- Pros
  - Finds a unique solution
- Cons
  - A w that could be scanned could possibly not be scanned
    - e.g. L = {a, ab, bc}; w = abc will not be split into [a, bc]

Algorithm:

1. Run DFA on remaining input until it gets stuck
2. If in a non-accepting state, backtrack to the last seen accepting state
  - If no accepting state was found, then the input can't be scanned with Maximal Munch
3. Output a token corresponding to the current (accepting) state
4. Set DFA state to start state, and repeat from step 1

In A7:
```scala
def scanOne(input: List[Char], state: State, backtrack: (List[Char], State)): (List[Char], State) = ???
// Arguments:
//  input: rest of input to scan
//  state: current state of DFA
// Return value: (rest of input after token, accepting state reached on token)
```

### Context-free Languages
e.g. A DFA for arithmetic, such as `a + b * c - d`

(this only parses singly nested brackets)
```
          a-z
      ┌────────v
   ┌──┴┐       ┌───┐
 ─>│   │       │   │
   └┬──┘       └┬──┘
    │ ^─────────┘ ^
   (│   v,-,*,/   │)
    v ┌─────────v │
   ┌──┴┐  a-z  ┌──┴┐
   │   │       │   │
   └───┘       └┬──┘
      ^─────────┘
        v,-,*,/
```

Regular expressions can't express unlimited recursive structures. We want nesting in programming languages, so we need something more powerful than regular languages.

#### Context-free Grammars
Regular Expressions use iteration, Context-free Grammars use recursion

e.g.
- expr &rarr; ID \| expr op expr \| (expr)
- op &rarr; + \| - \| * \| /
- ID &rarr; a \| b \| c

Parsing of `(a+b)*c`
```
                 expr
                  │
           ┌──────┴──────────────┬───────────────┐
           │                     │               │
          expr                  op              expr
           │                     │               │
   ┌───────┼─────────────────┐   *               ID
   │       │                 │                   │
   (      expr               )                   c
           │
     ┌─────┴─────┬────────┐
     │           │        │
    expr         op      expr
     │           │        │
     ID          +        ID
     │                    │
     a                    b

```

A **context-free grammar (CFG)** is a 4-tuple (V, &Epsilon; P, S) where:
- V is a finite set of non-terminal symbols (variables) e.g. {expr, op}
- &Sigma; is a finite set of terminal symbols e.g. {ID, +, -, +, /, (, )}
- P is a finite set of production rules
- S &isin; V is the start non-terminated e.g. S = expr

Let:
- a, b, c, d, &isin; &Sigma; (terminal)
- A, B, C, D, &isin; V (non-terminal)
- W, X, Y, Z &isin; &Sigma; &cup; V (terminal or non-terminal)
- w, x, y, z &isin; &Sigma;\* (string of terminals)
- &alpha;, &beta;, &gamma;, &delta; &isin; (&Sigma; &cup; V)\* (string of terminal and non-terminal symbols)

&alpha;A&beta; **directly derives** &alpha;&gamma;&beta; if A &rarr; &gamma; &isin; P
- Use &rArr; as a shorthand
- e.g. expr &rArr; expr op expr &rArr; ID op expr
- Only one substitution is allowed per direct derivation. Multiple direct derivations are needed for multiple substitutions

&alpha; **derives** &alpha;<sub>n</sub> (0 or more &rArr; steps) if &alpha;<sub>1</sub> &rArr; ... &rArr; &alpha;<sub>n</sub>
- Use &rArr;\* as a shorthand
- e.g. expr &rArr;\* ID + ID

The **language generate/specified by** G=(V, &Sigma;, P, S) is L(G) = { w &isin; &Sigma;\* \| S &rArr;\* w }
- A language is **context-free** if there exists a grammar G that generates it
- A language may be specified by multiple grammars
  - It is undecidable whether two CFGs generate the same language

```
e.g. 1+2*3 = 7 or 9?

  WRONG

              e
              │
   ┌───┬──────┴──┐
   │   │         │
   │   │         │
   e   op        e
   │   │         │                 
   │   │     ┌───┴──┬─────┐
   ID  +     │      │     │
            expr    op    e
             │      │     │
             │      │     │
             ID     *     ID

  RIGHT

              e
              │
        ┌─────┴────────┬───────┐
        │              │       │
        e              op      e
        │              │       │
   ┌────┼─────┐        │       │
   │    │     │        *       ID
   e    op    e
   │    │     │
   │    │     │
   ID   +     ID

```

A CFG is **ambiguous** if it allows multiple parse trees for the same input string
- To specify languages precisely, we want unambiguous parse trees for the same input
- it is undecidable whether a grammar is ambiguous

We can design a grammar for desired **precedence** and **associativity**

e.g. unambiguous for the examples used:
- expr &rarr; expr + term \| term \| expr - term
- term &rarr; term * factor \| factor
- factor &rarr; ID
```
left-associativity: (3-2)-1 = 0 or 2?

                e
                │
    ┌──────┬────┴──────────┐
    │      │               │
    e      +               t
    │                      │
    │               ┌─────┬┴───┐
    t               │     │    │
    │               t     *    f
    │               │          │
    f               │          │
    │               f          ID
    │               │
    ID              │
                    ID
```

#### CYK (Cocke, Younger, Kasami) Parsing
- input: grammar G, input string w
- output: w &isin; L(G)? S &rArr;\* w? (output parse tree or derivation)

```scala
parse(alpha, w) = { // returns a sequence of parse trees if alpha =>* w for symbols in alpha
  if (alpha.isEmpty) {
    if (w.isEmpty) Some(Seq()) else None
  } else if (alpha == a,beta) { // starts with terminal
    if (w == a,z && parse(beta, z)) Some(a +: parse(beta, z).get) // Create a new tree node here
    else None
  } else if (alpha == A) {
    (A -> gamma in P).forEach {
      if (parse(gamma, w)) return Some(Seq(tree A where children are parse(gamma, w).get)) // Create new tree node here
    }
    None
  } else { // alpha = A, beta
    split(w == u,v).forEach { // for each ways of splitting w into u and v
      if (parse(A, u) && parse(beta, v)) return Some(parse(A, u).get ++ parse(beta, v).get)
    }
    None
  }
}
```

```
p(expr, ID + ID)
│ 
├─ p(ID, ID + ID)
│    p(epsilon, + ID) X
│
└─p(expr op expr, ID + ID) // u = epsilon (*<=expr), u = ID + ID (*<=op expr)
  ├─ p(expr, epsilon)    <────────────────────────────────────┐
  │  │                                                        │
  │  ├─p(ID, epsilon) X                                       │
  │  │                                                        │
  │  └─p(expr op expr, epsilon) // u = epsilon, u = epsilon   │
  │      p(expr, epsilon) X (memo) ───────────────────────────┘
  │        ...infinite loop
  └┬─p(expr, ID)
   │   p(ID, ID) √
   │
   └─p(op expr, ID)
```

Remember (memoize) values at (&alpha;, w) &rarr; Boolean (for validity testing) or Option\[Seq\[Tree\]\] (for parse tree)
- Possible values of &alpha;, w:
  - &alpha; = S or a suffix of a right-hand side of a production rule
  - w = substring of input
  - parse(&alpha;, w) &lrarr; recur(&alpha;, from, length)
  - parse(&alpha;, input[from..from+length-1])
  - Possible values:
    - &alpha;, O(1), from: O(\|input\|), length: O(\|input\|), table of size: O(\|input\|<sup>2</sup>)
    - Running time: O(\|input\|<sup>3</sup>)

Using the table (memoization):
- whenever `recur` returns, record result in table
- at the beginning of recur, check the table for current input before trying to compute a result
- before starting a computation, record it in the table as false

Parser comparison:

Category| CYK | Earley | LR(k) LR(1) | LL(k) LL(1)
--------|-----|--------|-------------|------------
time | O(n<sup>3</sup>) | O(n<sup>3</sup>) for ambiguous, O(n<sup>2</sup>) for unambiguous, O(n) for almost all LR(1) grammars | O(n) | O(n)
grammars | all | all | most unambiguous grammars, test if it's LR(1) to see if it's unambiguous (approximate test) | very few practical grammars, no left-associativity
difficulty | 1 lecture | 1.5 weeks | 3 weeks | 1.5 weeks


Let w = xaz &notin; L be an incorrect input. 
- Suppose &exist; y . xy &isin; L
- but &forall; v . xaV &notin; L
  - a is the point where the error is
- A parser has the **Correct Prefix Property (CPP)** if it rejects xaz as soon as it processes xa.

To **augment** a grammar G with start symbol S means:
- add terminals BOF, EOF to &Sigma;
- add a new start non-terminal S'
- add a rule S' &rarr; BOF S EOF
  - This means anything derived from S' will always have a terminal in it

#### LR(1) parsing
- Let D = { &alpha; &rArr; &beta; \| &alpha; &rArr; &beta; is a step in some right-canonical derivation of some input w }
  - A derivation is **right-canonical** if each derivation step expends the right-most nonterminal
  - e.g. expr &rArr; expr op expr
    - Next step in right-canonical derivation would be expr op ID
    - Next step in left-canonical derivation would be ID op expr
- Let b be some terminal in &alpha; that is not followed by any non-terminals
- Decompose &alpha; = &gamma;by and &beta; = &delta;by
- Define F(&delta;b) = { &gamma; \| &exist; z . &gamma;bz &rArr; &delta;bz &isin; D  }
  - In the set D of all derivation steps of all derivations, this one appears, starting with &delta;b, coming from something starting from &gamma;b
  - &alpha; &isin; F(&delta;b)
- If for all &alpha; &rArr; &sigma;by &isin; D, \|F(&sigma;b)\| = 1, then the gramm ar is LR(1).

Algorithm (rough idea)
```scala
let beta = input string
while (beta != S) {
  find alpha element of F(beta)
  output s"$alpha => &beta"
  beta = alpha
}
```

What needs to be added:
- efficient implementation of the algorithm
- algorithm to compute F(&beta;)

### Context-Sensitive Analysis
Purpose
- reject programs that satisfy a grammar but are still invalid
- compute information needed to generate code

For Lacs:
1. Resolve names/symbols
  - Connect uses of symbols/names to the declarations
    - Symbol tables
  - detect undeclare/duplicate names
2. compute and check types
  - What is a type?
    - a set of values (in the real world)
    - an interpretation of sequences of bits
    - proof that a value is in a certain set

Uses of types
- ensure consistent use of operations (e.g. `1 + "foo"`)
- give meaning to operations (e.g. `1 + 2` vs `"1" + "2"`)
- keep track of intended interpretation of bits
- ensure correctness of programs

Lacs types
- Int
  - integers between -2<sup>31</sup> to 2<sup>31</sup>-1 with arithmetic modulo 2<sup>32</sup>
- (type, ...) =&gt; type
  - functions that take arguments of the specified types, return a value of the specified type

A **type system** is a set of rules that compute the type of an expression from the types of its subexpressions.
- A type system is **sound** if, when it computes a type &tau; for expression e (e:&tau;), then e evaluates to a value v &isin; &tau;
  - If e: &tau; and e &rarr;* v, then v &isin; &tau;
    - typing rules ... operational semantics
  - In our implementation, a **symbol table** maps names to either variables or procedures

#### Lacs type inference rules
```
  Premises
__________            means if premises then conclusion
Conclusion                                              

|¬ |- e : tau         means in scope |¬, e has type tau

hastype(|¬, e, tao)   means the same



__________
 NUM: Int


|¬(ID) = tau
_____________
|¬ |- ID : tau


Let E in {expras, expra, expr, term, factor}

                |¬ |- E1 : Int
                |¬ |- E2 : Int
_______________________________
      |¬ |- E1 + E2 : Int
               -
               *
               /
               %


               |¬(ID) = tau
              |¬ |- E : tau
____________________________
     |¬ |- ID = E : tau


        |¬ |- E1 : tau1   
        |¬ |- E2 : tau2
________________________
  |¬ |- E1 ; E2 : tau2


                        |¬ |- E1 : Int
                        |¬ |- E2 : Int
                        |¬ |- E3 : tau
                        |¬ |- E4 : tau
______________________________________
 |¬ |- if (E1 == E2) E3 else E4 : tau
              !=
              >=
              <=


 |¬ |- E' : (tau-) => tau'
  forall i . |¬ |- Ei : Ti
___________________________
       |¬ |- E' (E-)


forall i . |¬, vardef-, vardef'-, defdef- |- defdef i wf
             |¬, vardef-, vardef'-, defdef- |- E : tau
_____________________________________________________
    def ID(vardef-): tau = {vardef- defdef- E} wf


forall i . defdef- |- defdef i wf
_________________
empty env |- defdef- wf
```

### Assignment 10
```

    +----------+                +-------------+                    ++
    |          |  A7 (scanner)  |             |   A8 (parser)     ++++
    | program  +--------------->|   tokens    +--------------->  ++  ++  A9 (parse tree)
    |          |                |             |                 ++    ++     
    +----------+                +-------------+                -+--+---+-
                                                                   |
                                         context-sensitive <-------+
                                            information           A10
                                         scopes and types  --------+
                                                                   |
                                                                   v
                                                        +--------------------+
                                                        |                    |
                                                        |    intermediate    |
                                                        |   representation   |
                                                        |       (code)       |
                                                        |                    |
                                                        +----------+---------+
                                                                   |
                                                                   |
                             +-----------------------+             |  A1-6
                             |                       |             |
                             |   machine language    |<------------+
                             |                       |
                             +-----------------------+

```

## Memory Management

### Heap
A **heap** is a data structure to manage memory that can be allocated/freed at any time
- Operations:
  - allocate, new, malloc
    - size determined at runtime
  - free, delete
- Extra memory is needed for metadata to keep track of what is used/free

Which blocks are used/free?
1. add a bit in the header of each block to indicate if it is free or used
2. linked list of free blocks

```
1.
 +-+-------------+
 | | size        |
 +-+-------------+
 |^ free/used    |
 |     bit       |
 |               |
 |               |
 |               |
 |               |
 |               |
 +---------------+

2.
freelist
 V
 +---------------+  
 | size          |
 +---------------+
 | next          +--+
 +---------------+  |
 |               |  |
 |               |  |
 | free          |  |
 |               |  |
 +---------------+  |
                    |
                    |
 +---------------+  |
 | size          |  |
 +---------------+  |
 | next          |  |
 +---------------+  |
 |               |  |
 |               |  |
 | used          |  |
 |               |  |
 +---------------+  |
                    |
                    |
 +---------------+  |
 | size          | <+
 +---------------+  
 | next          +-------|
 +---------------+  
 |               |  
 |               |  
 | free          | 
 |               |  
 +---------------+
```

```
      +-----------------+
  100 | 8               |
      +-----------------+
  104 | freelist        +--+
      +-----------------+  |
  108 | 36              | <+
      +-----------------+
  112 |                 +--+
      +-----------------+  |
      |                 |  |
      |                 |  |
      |                 |  |
  140 |                 |  |
      +-----------------+  |
  144                 <----+

```

```scala
def size(block) = deref(block)
def next(block) = deref(block+4)
def setSize(block, size) = assignToAddr(block, size)
def setNext(block, next) = assignToAddr(block+4, next)
def init() = {
  val block = heapStart + 8 // 100 + 8
  setSize(heapStart, 8)
  setNext(heapStart, block)
  setSize(block, heapSize - 8) // 44 - 8
  setNext(block, heapStart + heapSize)
}

def malloc(wanted) = {
  def find(previous) = {
    val current = next(previous)
    if (size(current) < wanted + 4) {
      find(current)
    } else {
      if (size(current) > wanted + 12) {
        //split block
        val newBlock = current + wanted + 4
        setSize(newBlock, size(current) - size(wanted + 4))
        setNext(newBlock, next(current))
        setSize(current, wanted + 4)
        setNext(previous, newBlock)
      } else {
        setNext(previous, next(current))
      }
      setNext(previous, next(current))
      current
    }
  }
}

def free(toFree) = {
  def find(previous) = {
    val current = next(previous)
    if (current < toFree) {
      find(current)
    } else {
      if (toFree + size(toFree) == current && current < heapStart + heapSize) {
        // merge with current
        setSize(toFree, size(toFree)+size(current))
        setNext(toFree, next(current))
      } else {
        setNext(toFree, current)
      }
      if (previous + size(previous) == toFree && previous != heapStart) {
        // merge with previous block
        setSize(previous, size(previous) + size(toFree))
        setNext(previous, next(toFree))
      } else {
        setNext(previous, toFree)
      }
    }
  }
}
```

A heap is **fragmented**if the free space is split into small blocks.
- We can't allocate one large block even though there is enough free total space.
- Fragmentation can make an arbitrary fraction of the heap unuseable

Compaction
- copy all used blocks to the beginning of the heap
- update all pointers in the used blocks to the new locations

We need to identify which words in memory are addresses, so we need sound types.
- For Lacs variables, this means ones with `isPointer` set

New chunk diagram:
```
+---------------+
| size          |
+---------------+
| 3 (number of  |
|    pointers)  |
+---------------+
|               |
| pointer vars  |
|               |
+---------------+
|               |
|  other vars   |
|               |
+---------------+
```

After compaction, allocation is simple/constant time (increment a pointer).
- The cost per allocation/free operation is small.
- However, compaction takes time, so it is not ideal for real-time uses.

Which blocks should we compact? A block is **live** or **dead** if it will or will not be accessed in the future.
- The goal is to identify dead blocks automatically
- A block is **reachable** if:
  - its address is stored in the stack (or register), or
  - its address is stored in some other reachable block
- live &rArr; reachable
- unreachable &rArr; dead


### Cheney's Copying Garbage Collector, 1970
- compact blocks pointed to by the **roots** (stack, registers, but only stack for A11)
- compact by the already compacted blocks
- split heap into two **semi-spaces**
  - allocate in the **from-space**
  - compact and copy to the **to-space**
  - switch them after each garbage collection (compaction) run

```
              +------------+
              |            |
              | code       |
              |            |
              +------------+
    heapStart | used       |
              |............|
              |            | heapPointer
              | from-space |
              |            |
              +------------+
   heamMiddle | to-space   | semiSpaceTop
              |            |
              +------------+
      heapTop |            |
              | stack      |
              |            |
              +------------+
```

```scala
def init = {
  heapPointer = heapStart
  semiSpaceTop = heapMiddle
}
def allocate(wanted) = {
  if (heapPointer + wanted > semispaceTop) {
    gc()
  }
  val ret = heapPointer
  heapPointer = heapPointer + wanted
  ret
}
def gc = {
  // Swap segments of memory
  val newBottom =
    if (semiSpaceTop == heapMiddle) heapMiddle
    else heapStart
  var free = newBottom
  var scan = dynamicLink // top of stack
  while (scan < memSize) {
    forwardPtrs(scan) // will also increment free
    scan = scan + size(scan)
  }
  scan = newBottom
  while (scan < free) {
    forwardPtrs(scan)
    scan = scan + size(scan)
  }
  semispaceTop = newBottom + semiSpaceSize
  heapPointer = free
}

def forwardPtrs(block) = {
  for each offset o in block that holds a pointer {
    assignToAddr(block + o, copy(deref(block + o)))
  }
}

def copy(block) = {
  if (block is not in from-space) {
    block;
  } else {
    if (size(block) >= 0) { // not yet copied
      copyChunk(free, block)
      setNext(block, free) // forwarding address
      setSize(block, -size(block))
      free = free + size(free)
    }
    next(block)
  }
}
```

- make size variable in chunk negative to indicate that it has been moved
- save new location in number-of-pointers variable
- this is ok because it's in the from space anyway

Time complexity
- Allocation: O(1)
- GC: O(\|reachable memory\|), often less than O(\|heap\|)
  - Cost per allocation depends on frequency of GC
  - this depends on fraction of the heap that is reachable

### Generational GC
- observation: most memory lives long or dies young
- idea: more than 2 semispaces
  - small ones for blocks that die young, collect frequently
  - larger ones for blocks that live long, collected rarely

## The Lambda Calculus
e &rarr; v \| &lambda;v.e \| e e
- &lambda;v.e is the **lambda abstraction**
- e e is the **function application**

(&lambda;v.e<sub>1</sub>) e<sub>2</sub> &rarr; e<sub>1</sub>\[e<sub>2</sub>/v\]
- \[e<sub>2</sub>/v\] is a **substitution**
- this rule is called **&beta;-reduction**
- e.g. (&lambda;v . v v d) ((a b) c)
  - ( (a b) c ) ( (a b) c ) d

```
e1 --> e1'
______________
e1e2 --> e1'e2

e2 --> e2'
______________
e1e2 --> e1e2'

e --> e'
__________________________
lambda v.e --> lambda v.e'
```

```scala
abstract class Expr
case class Var(name: String) extends Expr
case class Lambda(name: String, expr: Expr) extends Expr
case class Apply(function: Expr, argument: Expr) extends Expr

val ID = Lambda("x", Var("x")) // lambda x . x
val IDID = Apply(ID, ID) // (lambda x . x) (lambda x . x)

val step: PartialFunction[Expr, Expr] = {
  case Apply(Lambda(variable, e1), e2) =>
    subst(e1, variable, e2)
}
def subst(expr: Expr, name: String, replacement: Expr): Expr = expr match {
  case Var(name2) =>
    if (name == name2) replacement
    else expr
  case Apply(e1, e2) => Apply(
    subst(e1, name, replacement),
    subst(e2, name, replacement)
  )
  case Lambda(name2, expr2) =>
}
```

- TRUE is a function that takes two arguments and returns the first
  - TRUE = &lambda;x.&lambda;y.x
- FALSE is a function that takes two arguments and returns the second
  - FALSE = &lambda;x.&lambda;y.y
- An if statement is a function that takes a condition, a then, and an else, and applies either the then or else depending on the result of condition
  - IF = &lambda;cond.&lambda;then.&lambda;else cond then else
  - e.g. (&lambda;cond.&lambda;then.&lambda;else cond then else) TRUE t f &rArr; t
- A number n is a function call applied n times. The n+1<sup>st</sup> number is n applied once more
  - e.g. ZERO = &lambda;f.&lambda;x.x
  - e.g. ONE = &lambda;f.&lambda;x.f x
  - e.g. TWO = &lambda;f.&lambda;x.f (f x)
  - e.g. SUCC = &lambda;.n.&lambda;f.&lambda;x.f (n f x)
  - e.g. THREE = (SUCC) TWO
- Addition of m and x is done by applying x m-times
  - e.g. PLUS = &lambda;m.&lambda;n.&lambda;f;&lambda;x.n f (m f x)
